<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Apache Flink (incubating): Use Stratosphere with Amazon Elastic MapReduce</title>
    <link rel="stylesheet" href="//css/bootstrap.css">
    <link rel="stylesheet" href="//css/bootstrap-lumen-custom.css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
    <script src="bootstrap.js"></script>
  </head>
  <body>

<nav class="navbar navbar-default navbar-static-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="//index.html">Apache Flink</a>
    </div>

    <div class="collapse navbar-collapse" id="navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li class=""><a href="//index.html">Home</a></li>

        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown">Quickstart <b class="caret"></b></a>
          <ul class="dropdown-menu">
            <li><a href="//docs/setup_quickstart.html">Setup Flink</a></li>
            <li><a href="//docs/java_api_quickstart.html">Java API</a></li>
            <li><a href="//docs/scala_api_quickstart.html">Scala API</a></li>
          </ul>
        </li>

        <li>
          <a href="//downloads.html" class="">Downloads</a>
        </li>

        <li>
          <a href="//docs/index.html" class="">Documentation</a>
        </li>

        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown">Community <b class="caret"></b></a>
          <ul class="dropdown-menu">
            <li><a href="community.html#mailing-lists">Mailing Lists</a></li>
            <li><a href="community.html#issues">Issues</a></li>
            <li><a href="community.html#committers">Committers</a></li>
            <li class="divider"></li>
            <li><a href="how-to-contribute.html">How To Contribute</a></li>
          </ul>
        </li>

        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown">Project <b class="caret"></b></a>
          <ul class="dropdown-menu">
            <li><a href="project.html#history">History</a></li>
            <li><a href="https://wiki.apache.org/incubator/StratosphereProposal">Incubator Proposal</a></li>
            <li><a href="http://www.apache.org/licenses/LICENSE-2.0">License</a></li>
            <li><a href="https://github.com/apache/incubator-flink">Source Code</a></li>
          </ul>
        </li>
      </ul>
    </div>
  </div>
</nav>

    <div class="container">

<article>
  <h2>Use Stratosphere with Amazon Elastic MapReduce</h2>
  <p class="meta">18 Feb 2014</p>
    
  <div>
<div class="lead">Get started with Stratosphere within 10 minutes using Amazon Elastic MapReduce.</div>

<p>This step-by-step tutorial will guide you through the setup of Stratosphere using Amazon Elastic MapReduce.</p>

<h3 id="toc_0">Background</h3>

<p><a href="http://aws.amazon.com/elasticmapreduce/">Amazon Elastic MapReduce</a> (Amazon EMR) is part of Amazon Web services. EMR allows to create Hadoop clusters that analyze data stored in Amazon S3 (AWS&#39; cloud storage). Stratosphere runs on top of Hadoop using the <a href="http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/releasenotes.html">recently</a> released cluster resource manager <a href="http://hadoop.apache.org/docs/current2/hadoop-yarn/hadoop-yarn-site/YARN.html">YARN</a>. YARN allows to use many different data analysis tools in your cluster side by side. Tools that run with YARN are, for example <a href="https://giraph.apache.org/">Apache Giraph</a>, <a href="http://spark.incubator.apache.org/">Spark</a> or <a href="http://hortonworks.com/blog/introducing-hoya-hbase-on-yarn/">HBase</a>. Stratosphere also <a href="//docs/0.4/setup/yarn.html">runs on YARN</a> and that&#39;s the approach for this tutorial.</p>

<h3 id="toc_1">1. Step: Login to AWS and prepare secure access</h3>

<ul>
<li>Log in to the <a href="https://console.aws.amazon.com/console/home">AWS Console</a></li>
</ul>

<p>You need to have SSH keys to access the Hadoop master node. If you do not have keys for your computer, generate them:</p>

<div class="row" style="padding-top:15px">
    <div class="col-md-6">
<a data-lightbox="inputs" href="//img/blog/emr-security.png" data-lightbox="example-1"><img class="img-responsive" src="//img/blog/emr-security.png" /></a>
    </div>
    <div class="col-md-6">
        <ul>
            <li>Select <a href="https://console.aws.amazon.com/ec2/v2/home">EC2</a> and click on "Key Pairs" in the "NETWORK & SECURITY" section.</li>
            <li>Click on "Create Key Pair" and give it a name</li>
            <li>After pressing "Yes" it will download a .pem file.</li>
            <li>Change the permissions of the .pem file</li>

<div class="highlight"><pre><code class="bash">chmod og-rwx ~/work-laptop.pem 
</code></pre></div>

        </ul>
    </div>
</div>

<h3 id="toc_2">2. Step: Create your Hadoop Cluster in the cloud</h3>

<ul>
<li>Select <a href="https://console.aws.amazon.com/elasticmapreduce/vnext/">Elastic MapReduce</a> from the AWS console</li>
<li>Click the blue &quot;Create cluster&quot; button.</li>
</ul>

<div class="row" style="padding-top:15px">
    <div class="col-md-6">
<a data-lightbox="inputs" href="//img/blog/emr-hadoopversion.png" data-lightbox="example-1"><img class="img-responsive" src="//img/blog/emr-hadoopversion.png" /></a>
    </div>
    <div class="col-md-6">
        <ul>
            <li>Choose a Cluster name</li>
            <li>You can let the other settings remain unchanged (termination protection, logging, debugging)</li>
            <li>For the Hadoop distribution, it is very important to choose one with YARN support. We use <b>3.0.3 (Hadoop 2.2.0)</b> (the minor version might change over time)</li>
            <li>Remove all applications to be installed (unless you want to use them)</li>
            <li>Choose the instance types you want to start. Stratosphere runs fine with m1.large instances. Core and Task instances both run Stratosphere, but only core instances contain HDFS data nodes.</li>
            <li>Choose the <b>EC2 key pair</b> you've created in the previous step!</li>
        </ul>
    </div>
</div>

<ul>
<li>Thats it! You can now press the &quot;Create cluster&quot; button at the end of the form to boot it!</li>
</ul>

<h3 id="toc_3">3. Step: Launch Stratosphere</h3>

<p>You might need to wait a few minutes until Amazon started your cluster. (You can monitor the progress of the instances in EC2). Use the refresh button in the top right corner.</p>

<p>You see that the master is up if the field <b>Master public DNS</b> contains a value (first line), connect to it using SSH.</p>

<div class="highlight"><pre><code class="bash">ssh hadoop@&lt;your master public DNS&gt; -i &lt;path to your .pem&gt;
<span class="c"># for my example, it looks like this:</span>
ssh hadoop@ec2-54-213-61-105.us-west-2.compute.amazonaws.com -i ~/Downloads/work-laptop.pem
</code></pre></div>



(Windows users have to follow <a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-connect-master-node-ssh.html">these instructions</a> to SSH into the machine running the master.) </br></br>
Once connected to the master, download and start Stratosphere for YARN: 
<ul>
    <li>Download and extract Stratosphere-YARN</li>

<div class="highlight"><pre><code class="bash">wget http://stratosphere-bin.s3-website-us-east-1.amazonaws.com/stratosphere-dist-0.5-SNAPSHOT-yarn.tar.gz
<span class="c"># extract it</span>
tar xvzf stratosphere-dist-0.5-SNAPSHOT-yarn.tar.gz
</code></pre></div>

    <li>Start Stratosphere in the cluster using Hadoop YARN</li>


<div class="highlight"><pre><code class="bash"><span class="nb">cd </span>stratosphere-yarn-0.5-SNAPSHOT/
./bin/yarn-session.sh -n 4 -jm 1024 -tm 3000
</code></pre></div>


The arguments have the following meaning
    <ul>
            <li><code>-n</code> number of TaskManagers (=workers). This number must not exeed the number of task instances</li>
            <li><code>-jm</code> memory (heapspace) for the JobManager</li>
            <li><code>-tm</code> memory for the TaskManagers</li>
    </ul>
</ul>

Once the output has changed from 

<div class="highlight"><pre><code class="bash">JobManager is now running on N/A:6123
</code></pre></div>

to 

<div class="highlight"><pre><code class="bash">JobManager is now running on ip-172-31-13-68.us-west-2.compute.internal:6123
</code></pre></div>

Stratosphere has started the JobManager. It will take a few seconds until the TaskManagers (workers) have connected to the JobManager. To see how many TaskManagers connected, you have to access the JobManager's web interface. Follow the steps below to do that ...




<h3> 4. Step: Launch a Stratosphere Job</h3>

This step shows how to submit and monitor a Stratosphere Job in the Amazon Cloud.

<ul>
<li> Open an additional terminal and connect again to the master of your cluster. </li>

We recommend to create a SOCKS-proxy with your SSH that allows you to easily connect into the cluster. (If you've already a VPN setup with EC2, you can probably use that as well.)


<div class="highlight"><pre><code class="bash">ssh -D localhost:2001 hadoop@&lt;your master dns name&gt; -i &lt;your pem file&gt;
</code></pre></div>


Notice the <code>-D localhost:2001</code> argument: It opens a SOCKS proxy on your computer allowing any application to use it to communicate through the proxy via an SSH tunnel to the master node. This allows you to access all services in your EMR cluster, such as the HDFS NameNode or the YARN web interface.

<li>Configure a browser to use the SOCKS proxy. Open a browser with SOCKS proxy support (such as Firefox). Ideally, do not use your primary browser for this, since ALL traffic will be routed through Amazon.</li>

<div class="row" style="padding-top:15px">
    <div class="col-md-6">
<a data-lightbox="inputs" href="//img/blog/emr-firefoxsettings.png" data-lightbox="example-1"><img class="img-responsive" src="//img/blog/emr-firefoxsettings.png" /></a>
    </div>
    <div class="col-md-6">
        <ul>
            <li>To configure the SOCKS proxy with Firefox, click on "Edit", "Preferences", choose the "Advanced" tab and press the "Settings ..." button.</li>
            <li>Enter the details of the SOCKS proxy <b>localhost:2001</b>. Choose SOCKS v4.</li>
            <li>Close the settings, your browser is now talking to the master node of your cluster</li>
        </ul>
    </div>
</div>

<p></ul></p>

<p>Since you&#39;re connected to the master now, you can open several web interfaces: <br>
<b>YARN Resource Manager</b>: <code>http://&lt;masterIPAddress&gt;:9026/</code> <br>
<b>HDFS NameNode</b>: <code>http://&lt;masterIPAddress&gt;:9101/</code></p>

<p>You find the <code>masterIPAddress</code> by entering <code>ifconfig</code> into the terminal:</p>

<div class="highlight"><pre><code class="bash"><span class="o">[</span>hadoop@ip-172-31-38-95 ~<span class="o">]</span><span class="nv">$ </span>ifconfig
eth0      Link encap:Ethernet  HWaddr 02:CF:8E:CB:28:B2  
          inet addr:172.31.38.95  Bcast:172.31.47.255  Mask:255.255.240.0
          inet6 addr: fe80::cf:8eff:fecb:28b2/64 Scope:Link
          RX bytes:166314967 <span class="o">(</span>158.6 MiB<span class="o">)</span>  TX bytes:89319246 <span class="o">(</span>85.1 MiB<span class="o">)</span>
</code></pre></div>

<p><strong>Optional:</strong> If you want to use the hostnames within your Firefox (that also makes the NameNode links work), you have to enable DNS resolution over the SOCKS proxy. Open the Firefox config <code>about:config</code> and set <code>network.proxy.socks_remote_dns</code> to <code>true</code>.</p>

<p>The YARN ResourceManager also allows you to connect to <b>Stratosphere&#39;s JobManager web interface</b>. Click the <b>ApplicationMaster</b> link in the &quot;Tracking UI&quot; column.</p>

<p>To run the Wordcount example, you have to upload some sample data.</p>

<div class="highlight"><pre><code class="bash"><span class="c"># download a text</span>
wget http://www.gnu.org/licenses/gpl.txt
<span class="c"># upload it to HDFS:</span>
hadoop fs -copyFromLocal gpl.txt /input
</code></pre></div>

<p>To run a Job, enter the following command into the master&#39;s command line:</p>

<div class="highlight"><pre><code class="bash"><span class="c"># optional: go to the extracted directory</span>
<span class="nb">cd </span>stratosphere-yarn-0.5-SNAPSHOT/
<span class="c"># run the wordcount example</span>
./bin/stratosphere run -w -j examples/stratosphere-java-examples-0.5-SNAPSHOT-WordCount.jar  -a 16 hdfs:///input hdfs:///output
</code></pre></div>

<p>Make sure that the number of TaskManager&#39;s have connected to the JobManager.</p>

<p>Lets go through the command in detail:</p>

<ul>
<li><code>./bin/stratosphere</code> is the standard launcher for Stratosphere jobs from the command line</li>
<li>The <code>-w</code> flag stands for &quot;wait&quot;. It is a very useful to track the progress of the job.</li>
<li><code>-j examples/stratosphere-java-examples-0.5-SNAPSHOT-WordCount.jar</code> the <code>-j</code> command sets the jar file containing the job. If you have you own application, place your Jar-file here.</li>
<li><code>-a 16 hdfs:///input hdfs:///output</code> the <code>-a</code> command specifies the Job-specific arguments. In this case, the wordcount expects the following input <code>&lt;numSubStasks&gt; &lt;input&gt; &lt;output&gt;</code>.</li>
</ul>

<p>You can monitor the progress of your job in the JobManager webinterface. Once the job has finished (which should be the case after less than 10 seconds), you can analyze it there.
Inspect the result in HDFS using:</p>

<div class="highlight"><pre><code class="bash">hadoop fs -tail /output
</code></pre></div>

<p>If you want to shut down the whole cluster in the cloud, use Amazon&#39;s webinterface and click on &quot;Terminate cluster&quot;. If you just want to stop the YARN session, press CTRL+C in the terminal. The Stratosphere instances will be killed by YARN.</p>

<p><br><br>
<small>Written by Robert Metzger (<a href="https://twitter.com/rmetzger_">@rmetzger_</a>).</small></p>

  </div>
</article>

     <div class="footer">

<hr class="divider">

<p>Apache Flink is an effort undergoing incubation at The Apache Software
Foundation (ASF), sponsored by the Apache Incubator PMC. Incubation is
required of all newly accepted projects until a further review indicates that
the infrastructure, communications, and decision making process have
stabilized in a manner consistent with other successful ASF projects. While
incubation status is not necessarily a reflection of the completeness or
stability of the code, it does indicate that the project has yet to be fully
endorsed by the ASF.</p>

<p><img src="//img/apache-incubator-logo.png" alt="Incubator Logo"></p>

<p class="text-center"><a href="//privacy-policy.html">Privacy Policy<a></p>

      </div>
    </div>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="//js/bootstrap.min.js"></script>
  </body>
</html>
